{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verl Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The demo is verified on the image `hiyouga/verl:ngc-th2.6.0-cu126-vllm0.8.3-flashinfer0.2.2-cxx11abi0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify from the setup in [SimpleRL Zoo](https://github.com/hkust-nlp/simpleRL-reason?tab=readme-ov-file#training). Kudos to their awesome work on verifying RL with LLMs of various scales!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/root/verl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install `verl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Obtaining file:///root/verl\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (1.6.0)\n",
      "Requirement already satisfied: codetiming in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (1.4.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (3.5.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (0.3.8)\n",
      "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (1.3.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (0.15.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (16.1.0)\n",
      "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (2.13.4)\n",
      "Requirement already satisfied: pylatexenc in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (2.10)\n",
      "Requirement already satisfied: ray>=2.10 in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (2.43.0)\n",
      "Requirement already satisfied: tensordict<=0.6.2 in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (0.6.2)\n",
      "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (0.11.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (4.51.1)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (0.19.9)\n",
      "Requirement already satisfied: vllm<=0.8.2 in /usr/local/lib/python3.10/dist-packages (from verl==0.2.0.dev0) (0.8.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (8.1.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (1.0.8)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (4.24.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (1.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (3.10.1)\n",
      "Requirement already satisfied: aiohttp_cors in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: colorful in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (0.5.6)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (1.71.0)\n",
      "Requirement already satisfied: opencensus in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (0.11.4)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (2.11.3)\n",
      "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (0.20.0)\n",
      "Requirement already satisfied: smart_open in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (7.0.4)\n",
      "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.10->verl==0.2.0.dev0) (20.30.0)\n",
      "Requirement already satisfied: torch>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from tensordict<=0.6.2->verl==0.2.0.dev0) (2.6.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tensordict<=0.6.2->verl==0.2.0.dev0) (3.0.0)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict<=0.6.2->verl==0.2.0.dev0) (3.10.16)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (5.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (6.0.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (4.66.5)\n",
      "Requirement already satisfied: blake3 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (1.0.4)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (9.0.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.21.1)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.115.12)\n",
      "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (1.72.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (10.4.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (7.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.9.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.10.11)\n",
      "Requirement already satisfied: llguidance<0.8.0,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.7.13)\n",
      "Requirement already satisfied: outlines==0.1.11 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (1.2.2)\n",
      "Requirement already satisfied: xgrammar==0.1.16 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.1.16)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (26.1.0)\n",
      "Requirement already satisfied: msgspec in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.19.0)\n",
      "Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.10.0)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (7.2.1)\n",
      "Requirement already satisfied: mistral_common>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from mistral_common[opencv]>=1.5.4->vllm<=0.8.2->verl==0.2.0.dev0) (1.5.4)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.8.0)\n",
      "Requirement already satisfied: compressed-tensors==0.9.2 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.9.2)\n",
      "Requirement already satisfied: depyf==0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.18.0)\n",
      "Requirement already satisfied: watchfiles in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (1.0.5)\n",
      "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (2.0.7)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (1.14.0)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (1.11.1.1)\n",
      "Requirement already satisfied: numba==0.60.0 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.60.0)\n",
      "Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (2.6.0)\n",
      "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: xformers==0.0.29.post2 in /usr/local/lib/python3.10/dist-packages (from vllm<=0.8.2->verl==0.2.0.dev0) (0.0.29.post2)\n",
      "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from depyf==0.18.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba==0.60.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.43.0)\n",
      "Requirement already satisfied: interegular in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm<=0.8.2->verl==0.2.0.dev0) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm<=0.8.2->verl==0.2.0.dev0) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm<=0.8.2->verl==0.2.0.dev0) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm<=0.8.2->verl==0.2.0.dev0) (5.6.3)\n",
      "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm<=0.8.2->verl==0.2.0.dev0) (0.35.1)\n",
      "Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm<=0.8.2->verl==0.2.0.dev0) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm<=0.8.2->verl==0.2.0.dev0) (20250224)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm<=0.8.2->verl==0.2.0.dev0) (0.1.26)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (3.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.5.0->tensordict<=0.6.2->verl==0.2.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.10/dist-packages (from transformers->verl==0.2.0.dev0) (0.30.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->verl==0.2.0.dev0) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers->verl==0.2.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->verl==0.2.0.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->verl==0.2.0.dev0) (0.70.16)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core->verl==0.2.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core->verl==0.2.0.dev0) (4.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->verl==0.2.0.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->verl==0.2.0.dev0) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->verl==0.2.0.dev0) (2024.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata->verl==0.2.0.dev0) (2.0.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->verl==0.2.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->verl==0.2.0.dev0) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->verl==0.2.0.dev0) (4.2.2)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->verl==0.2.0.dev0) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->verl==0.2.0.dev0) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->verl==0.2.0.dev0) (70.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]>=2.10->verl==0.2.0.dev0) (2.3.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]>=2.10->verl==0.2.0.dev0) (24.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]>=2.10->verl==0.2.0.dev0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]>=2.10->verl==0.2.0.dev0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]>=2.10->verl==0.2.0.dev0) (4.0.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->verl==0.2.0.dev0) (1.16.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.46.1)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.0.7)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.27.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.0.20)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (2.2.0)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.34.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->verl==0.2.0.dev0) (4.0.12)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (0.20.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mistral_common[opencv]>=1.5.4->vllm<=0.8.2->verl==0.2.0.dev0) (4.11.0.86)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm<=0.8.2->verl==0.2.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm<=0.8.2->verl==0.2.0.dev0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm<=0.8.2->verl==0.2.0.dev0) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]>=2.10->verl==0.2.0.dev0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]>=2.10->verl==0.2.0.dev0) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]>=2.10->verl==0.2.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.10/dist-packages (from ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (13.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (2024.7.4)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.10->verl==0.2.0.dev0) (0.3.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->vllm<=0.8.2->verl==0.2.0.dev0) (3.19.2)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]>=2.10->verl==0.2.0.dev0) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]>=2.10->verl==0.2.0.dev0) (2.24.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart_open->ray[default]>=2.10->verl==0.2.0.dev0) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.52.0->vllm<=0.8.2->verl==0.2.0.dev0) (1.2.2)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (2.7.0)\n",
      "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.12.4)\n",
      "Requirement already satisfied: rich-toolkit>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.14.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->verl==0.2.0.dev0) (5.0.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.10->verl==0.2.0.dev0) (1.69.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.10->verl==0.2.0.dev0) (1.26.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.10->verl==0.2.0.dev0) (2.38.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->outlines==0.1.11->vllm<=0.8.2->verl==0.2.0.dev0) (2.1.5)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (1.1.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (15.0.1)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x->ray>=2.10->ray[default]>=2.10->verl==0.2.0.dev0) (0.8.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.10->verl==0.2.0.dev0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.10->verl==0.2.0.dev0) (4.9)\n",
      "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.10/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (13.7.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (1.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.10->verl==0.2.0.dev0) (0.6.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm<=0.8.2->verl==0.2.0.dev0) (0.1.2)\n",
      "Building wheels for collected packages: verl\n",
      "  Building editable for verl (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for verl: filename=verl-0.2.0.dev0-0.editable-py3-none-any.whl size=16801 sha256=7d1ad94ef6d22a86858d0fb7d77a8698d42013b75515779eaa6b121cb97fce9f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qxf0f01a/wheels/d4/f5/29/7c5bb62e9344bc78534719365f2fb772bb330dbd23de4b25d2\n",
      "Successfully built verl\n",
      "Installing collected packages: verl\n",
      "  Attempting uninstall: verl\n",
      "    Found existing installation: verl 0.2.0.dev0\n",
      "    Uninstalling verl-0.2.0.dev0:\n",
      "      Successfully uninstalled verl-0.2.0.dev0\n",
      "Successfully installed verl-0.2.0.dev0\n"
     ]
    }
   ],
   "source": [
    "! pip install -e \".[vllm]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|█████████| 8/8 [00:00<00:00, 82.83ba/s]\n",
      "Creating parquet from Arrow format: 100%|████████| 2/2 [00:00<00:00, 366.63ba/s]\n"
     ]
    }
   ],
   "source": [
    "os.environ.update({\n",
    "    \"TRAIN_FILE\": \"/root/data/gsm8k/train.parquet\",\n",
    "    \"TEST_FILE\": \"/root/data/gsm8k/test.parquet\",\n",
    "})\n",
    "\n",
    "! python examples/data_preprocess/gsm8k.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306\n"
     ]
    }
   ],
   "source": [
    "os.environ.update({\n",
    "    \"MODEL_ID\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "})\n",
    "\n",
    "! huggingface-cli download \"${MODEL_ID}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please search for \"val-core/...\" in the output for core validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.update({\"VLLM_USE_V1\": \"1\", \n",
    "                   \"VERL_PPO_LOGGING_LEVEL\": \"INFO\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-16 11:23:41,891\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m {'actor_rollout_ref': {'actor': {'checkpoint': {'contents': ['model',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                                              'optimizer',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                                              'extra']},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'clip_ratio': 0.2,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'clip_ratio_c': 10.0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'clip_ratio_high': 0.2,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'clip_ratio_low': 0.2,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'entropy_coeff': 0.001,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'fsdp_config': {'fsdp_size': -1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                                  'optimizer_offload': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                                  'param_offload': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                                  'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'grad_clip': 1.0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'kl_loss_coef': 0.001,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'kl_loss_type': 'low_var_kl',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'loss_agg_mode': 'token-mean',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'optim': {'lr': 5e-07,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                            'lr_warmup_steps': 10,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                            'lr_warmup_steps_ratio': 0.0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                            'min_lr_ratio': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                            'total_training_steps': -1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                            'warmup_style': 'constant',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                            'weight_decay': 0.01},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'ppo_epochs': 1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'ppo_max_token_len_per_gpu': 8192,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'ppo_micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'ppo_micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'ppo_mini_batch_size': 128,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'shuffle': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'ulysses_sequence_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'use_dynamic_bsz': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'use_kl_loss': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'use_torch_compile': True},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                        'hybrid_engine': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                        'model': {'enable_gradient_checkpointing': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'external_lib': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'override_config': {},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'path': 'Qwen/Qwen2.5-1.5B-Instruct',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'use_liger': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                  'use_remove_padding': True},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                        'ref': {'fsdp_config': {'param_offload': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                                'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                'log_prob_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                'log_prob_micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                'log_prob_micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                'log_prob_use_dynamic_bsz': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                'ulysses_sequence_parallel_size': 1},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                        'rollout': {'disable_log_stats': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'do_sample': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'dtype': 'bfloat16',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'enable_chunked_prefill': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'enforce_eager': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'engine_kwargs': {'swap_space': None},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'free_cache_engine': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'gpu_memory_utilization': 0.8,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'ignore_eos': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'load_format': 'dummy_dtensor',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'log_prob_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'log_prob_micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'log_prob_micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'log_prob_use_dynamic_bsz': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'max_model_len': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'max_num_batched_tokens': 10240,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'max_num_seqs': 1024,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'n': 8,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'name': 'vllm',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'prompt_length': 512,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'response_length': 1024,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'temperature': 1.0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'tensor_model_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'top_k': -1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'top_p': 1.0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'use_fire_sampling': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                    'val_kwargs': {'do_sample': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                                   'n': 1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                                   'temperature': 1.0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                                   'top_k': -1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                                   'top_p': 0.95}}},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  'algorithm': {'adv_estimator': 'grpo',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                'gamma': 1.0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                'kl_ctrl': {'horizon': 10000,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                            'kl_coef': 0.0001,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                            'target_kl': 0.1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                            'type': 'fixed'},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                'kl_penalty': 'kl',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                'lam': 1.0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                'use_kl_in_reward': True},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  'critic': {'checkpoint': {'contents': ['model', 'optimizer', 'extra']},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'cliprange_value': 0.5,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'forward_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'forward_micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'forward_micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'grad_clip': 1.0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'model': {'enable_gradient_checkpointing': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'external_lib': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'fsdp_config': {'fsdp_size': -1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                       'optimizer_offload': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                       'param_offload': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                       'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'override_config': {},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'path': '~/models/deepseek-llm-7b-chat',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B-Instruct',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'use_remove_padding': False},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'optim': {'lr': 1e-05,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'lr_warmup_steps_ratio': 0.0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'min_lr_ratio': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'total_training_steps': -1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'warmup_style': 'constant',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                       'weight_decay': 0.01},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'ppo_epochs': 1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'ppo_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'ppo_micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'ppo_micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'ppo_mini_batch_size': 128,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'rollout_n': 8,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'shuffle': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'ulysses_sequence_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m             'use_dynamic_bsz': True},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  'data': {'custom_cls': {'name': None, 'path': None},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'filter_overlong_prompts': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'filter_overlong_prompts_workers': 1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'image_key': 'images',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'max_prompt_length': 512,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'max_response_length': 1024,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'prompt_key': 'prompt',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'return_raw_chat': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'return_raw_input_ids': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'reward_fn_key': 'data_source',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'shuffle': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'tokenizer': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'train_batch_size': 128,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'train_files': ['/root/data/gsm8k/train.parquet'],\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'truncation': 'error',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'val_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m           'val_files': ['/root/data/gsm8k/test.parquet']},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  'reward_model': {'enable': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                   'forward_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                   'max_length': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                   'micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                   'micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                   'model': {'external_lib': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                             'fsdp_config': {'fsdp_size': -1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                             'param_offload': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                                             'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B-Instruct',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                             'use_remove_padding': False},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                   'reward_manager': 'naive',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                   'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                   'ulysses_sequence_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m                   'use_dynamic_bsz': True},\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  'trainer': {'balance_batch': True,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'critic_warmup': 0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'default_hdfs_dir': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'default_local_dir': 'checkpoints/verl-demo/grpo-gsm8k-qwen2.5-1.5b-instruct',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'del_local_ckpt_after_load': False,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'experiment_name': 'grpo-gsm8k-qwen2.5-1.5b-instruct',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'log_val_generations': 0,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'logger': ['console'],\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'max_actor_ckpt_to_keep': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'max_critic_ckpt_to_keep': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'n_gpus_per_node': 1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'nnodes': 1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'project_name': 'verl-demo',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'ray_wait_register_center_timeout': 300,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'resume_from_path': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'resume_mode': 'disable',\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'save_freq': -1,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'test_freq': 5,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'total_epochs': 20,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'total_training_steps': None,\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m              'val_before_train': True}}\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [validate_config] All configuration checks passed successfully!\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m dataset len: 7473\n",
      "Generating train split: 7473 examples [00:00, 397237.61 examples/s]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m dataset len: 1319\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Size of train dataloader: 58\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Total training steps: 1160\n",
      "Generating train split: 1319 examples [00:00, 240680.72 examples/s]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m WARNING:2025-04-16 11:23:52,342:Waiting for register center actor rz9xGj_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Model config after override: Qwen2Config {\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"architectures\": [\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m     \"Qwen2ForCausalLM\"\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   ],\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"attention_dropout\": 0.0,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"eos_token_id\": 151645,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"hidden_act\": \"silu\",\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"hidden_size\": 1536,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"initializer_range\": 0.02,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"intermediate_size\": 8960,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"max_position_embeddings\": 32768,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"max_window_layers\": 21,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"model_type\": \"qwen2\",\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"num_attention_heads\": 12,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"num_hidden_layers\": 28,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"num_key_value_heads\": 2,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"pad_token_id\": 151643,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"rms_norm_eps\": 1e-06,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"rope_scaling\": null,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"rope_theta\": 1000000.0,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"sliding_window\": 32768,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"tie_word_embeddings\": true,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"torch_dtype\": \"bfloat16\",\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"transformers_version\": \"4.51.1\",\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"use_cache\": true,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"use_sliding_window\": false,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"vocab_size\": 151936\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m }\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m \n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m [rank0]:[W416 11:24:02.577787498 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m NCCL version 2.21.5+cuda12.4\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/_init_utils.py:444: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Qwen2ForCausalLM contains 1.54B parameters\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m wrap_policy: functools.partial(<function _or_policy at 0x7f6d71a11bd0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f6d71a11ab0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Actor use_remove_padding=True\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Model config after override: Qwen2Config {\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"architectures\": [\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m     \"Qwen2ForCausalLM\"\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   ],\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"attention_dropout\": 0.0,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"eos_token_id\": 151645,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"hidden_act\": \"silu\",\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"hidden_size\": 1536,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"initializer_range\": 0.02,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"intermediate_size\": 8960,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"max_position_embeddings\": 32768,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"max_window_layers\": 21,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"model_type\": \"qwen2\",\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"num_attention_heads\": 12,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"num_hidden_layers\": 28,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"num_key_value_heads\": 2,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"pad_token_id\": 151643,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"rms_norm_eps\": 1e-06,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"rope_scaling\": null,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"rope_theta\": 1000000.0,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"sliding_window\": 32768,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"tie_word_embeddings\": true,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"torch_dtype\": \"bfloat16\",\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"transformers_version\": \"4.51.1\",\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"use_cache\": true,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"use_sliding_window\": false,\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   \"vocab_size\": 151936\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m }\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m \n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/_init_utils.py:444: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Qwen2ForCausalLM contains 1.54B parameters\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m wrap_policy: functools.partial(<function _or_policy at 0x7f6d71a11bd0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f6d71a11ab0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Total steps: 1160, num_warmup_steps: 10\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Actor use_remove_padding=True\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m Before building vllm rollout, memory allocated (GB): 8.64726972579956, memory reserved (GB): 10.0078125\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m WARNING 04-16 11:24:17 [cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m WARNING 04-16 11:24:18 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6ab1eaa7a0>\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m kwargs: {'n': 8, 'logprobs': 0, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1.0, 'ignore_eos': False}\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m After building vllm rollout, memory allocated (GB): 73.02916955947876, memory reserved (GB): 75.5625\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m After building sharding manager, memory allocated (GB): 73.02916955947876, memory reserved (GB): 75.5625\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Using LocalLogger is deprecated. The constructor API will change \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True}\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/_state_dict_utils.py:773: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/_state_dict_utils.py:711: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:24:22,199:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m validation generation end\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [prompt] system\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m user\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after \"####\".\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m assistant\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [response] To solve this problem, let's break it down into steps:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 1. First, calculate the total number of eggs laid per day:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    16 eggs/day\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 2. Janet eats 3 eggs for breakfast every day:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    16 eggs - 3 eggs = 13 eggs remaining for muffins\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 3. She bakes muffins with 4 of those remaining eggs:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    13 eggs - 4 eggs = 9 eggs\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 4. She sells the remaining eggs at the farmers' market:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    Eggs sold: 9\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 5. Each egg is sold for $2:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    Earnings from selling eggs: 9 eggs * $2 = $18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m So, Janet makes $18 every day at the farmers' market.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m #### Final answer: 18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [ground_truth] 18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [score] 0.0\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m (\"Initial validation metrics: {'val-core/openai/gsm8k/reward/mean@1': \"\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  \"0.10841546626231995, 'val-aux/openai/gsm8k/reward/std@1': 0.0, \"\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  \"'val-core/openai/gsm8k/reward/best@1/mean': 0.10841546626231995, \"\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  \"'val-core/openai/gsm8k/reward/best@1/std': 0.0, \"\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  \"'val-aux/openai/gsm8k/reward/worst@1/mean': 0.10841546626231995, \"\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m  \"'val-aux/openai/gsm8k/reward/worst@1/std': 0.0}\")\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:0 - val-core/openai/gsm8k/reward/mean@1:0.108 - val-aux/openai/gsm8k/reward/std@1:0.000 - val-core/openai/gsm8k/reward/best@1/mean:0.108 - val-core/openai/gsm8k/reward/best@1/std:0.000 - val-aux/openai/gsm8k/reward/worst@1/mean:0.108 - val-aux/openai/gsm8k/reward/worst@1/std:0.000\n",
      "Training Progress:   0%|          | 0/1160 [00:00<?, ?it/s]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:25:19,595:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:1 - global_seqlen/min:384399.000 - global_seqlen/max:384399.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:384399.000 - global_seqlen/balanced_max:384399.000 - global_seqlen/mean:384399.000 - actor/reward_kl_penalty:0.000 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.373 - actor/pg_loss:0.018 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.388 - perf/mfu/actor:0.652 - perf/max_memory_allocated_gb:96.192 - perf/max_memory_reserved_gb:102.457 - perf/cpu_memory_used_gb:10.240 - actor/lr:0.000 - critic/score/mean:0.135 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.135 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.018 - critic/advantages/max:2.475 - critic/advantages/min:-2.132 - critic/returns/mean:-0.018 - critic/returns/max:2.475 - critic/returns/min:-2.132 - response_length/mean:270.093 - response_length/max:1024.000 - response_length/min:4.000 - response_length/clip_ratio:0.001 - prompt_length/mean:105.297 - prompt_length/max:170.000 - prompt_length/min:66.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:26.414 - timing_s/old_log_prob:11.969 - timing_s/ref:15.451 - timing_s/adv:0.205 - timing_s/update_actor:43.532 - timing_s/step:97.624 - timing_per_token_ms/gen:0.096 - timing_per_token_ms/ref:0.040 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:384399.000 - perf/time_per_step:97.624 - perf/throughput:3937.541\n",
      "Training Progress:   0%|          | 1/1160 [01:37<31:30:22, 97.86s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:26:57,233:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:2 - global_seqlen/min:381533.000 - global_seqlen/max:381533.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:381533.000 - global_seqlen/balanced_max:381533.000 - global_seqlen/mean:381533.000 - actor/reward_kl_penalty:-0.000 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.382 - actor/pg_loss:0.013 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.431 - perf/mfu/actor:0.654 - perf/max_memory_allocated_gb:100.382 - perf/max_memory_reserved_gb:107.365 - perf/cpu_memory_used_gb:10.286 - actor/lr:0.000 - critic/score/mean:0.128 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.128 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.013 - critic/advantages/max:2.475 - critic/advantages/min:-2.297 - critic/returns/mean:-0.013 - critic/returns/max:2.475 - critic/returns/min:-2.297 - response_length/mean:268.435 - response_length/max:919.000 - response_length/min:5.000 - response_length/clip_ratio:0.000 - prompt_length/mean:104.156 - prompt_length/max:189.000 - prompt_length/min:70.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:24.991 - timing_s/old_log_prob:11.506 - timing_s/ref:11.201 - timing_s/adv:0.207 - timing_s/update_actor:43.070 - timing_s/step:91.018 - timing_per_token_ms/gen:0.091 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:381533.000 - perf/time_per_step:91.018 - perf/throughput:4191.834\n",
      "Training Progress:   0%|          | 2/1160 [03:08<30:11:13, 93.85s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:28:28,336:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:3 - global_seqlen/min:386441.000 - global_seqlen/max:386441.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:386441.000 - global_seqlen/balanced_max:386441.000 - global_seqlen/mean:386441.000 - actor/reward_kl_penalty:0.000 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.353 - actor/pg_loss:0.017 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.364 - perf/mfu/actor:0.658 - perf/max_memory_allocated_gb:100.382 - perf/max_memory_reserved_gb:107.465 - perf/cpu_memory_used_gb:10.298 - actor/lr:0.000 - critic/score/mean:0.111 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.111 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.018 - critic/advantages/max:2.475 - critic/advantages/min:-2.250 - critic/returns/mean:-0.018 - critic/returns/max:2.475 - critic/returns/min:-2.250 - response_length/mean:272.884 - response_length/max:943.000 - response_length/min:4.000 - response_length/clip_ratio:0.000 - prompt_length/mean:104.500 - prompt_length/max:183.000 - prompt_length/min:65.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:25.237 - timing_s/old_log_prob:11.183 - timing_s/ref:11.571 - timing_s/adv:0.205 - timing_s/update_actor:43.394 - timing_s/step:91.633 - timing_per_token_ms/gen:0.090 - timing_per_token_ms/ref:0.030 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:386441.000 - perf/time_per_step:91.633 - perf/throughput:4217.262\n",
      "Training Progress:   0%|          | 3/1160 [04:40<29:50:16, 92.84s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:29:59,983:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:4 - global_seqlen/min:388842.000 - global_seqlen/max:388842.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:388842.000 - global_seqlen/balanced_max:388842.000 - global_seqlen/mean:388842.000 - actor/reward_kl_penalty:0.000 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.413 - actor/pg_loss:0.027 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.453 - perf/mfu/actor:0.658 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.465 - perf/cpu_memory_used_gb:10.290 - actor/lr:0.000 - critic/score/mean:0.152 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.152 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.028 - critic/advantages/max:2.475 - critic/advantages/min:-2.182 - critic/returns/mean:-0.028 - critic/returns/max:2.475 - critic/returns/min:-2.182 - response_length/mean:274.033 - response_length/max:1024.000 - response_length/min:4.000 - response_length/clip_ratio:0.001 - prompt_length/mean:105.695 - prompt_length/max:215.000 - prompt_length/min:69.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:27.063 - timing_s/old_log_prob:11.266 - timing_s/ref:11.368 - timing_s/adv:0.206 - timing_s/update_actor:43.694 - timing_s/step:93.634 - timing_per_token_ms/gen:0.096 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:388842.000 - perf/time_per_step:93.634 - perf/throughput:4152.808\n",
      "Training Progress:   0%|          | 4/1160 [06:14<29:54:50, 93.16s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:31:33,634:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True}\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:33:07,767:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m validation generation end\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [prompt] system\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m user\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after \"####\".\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m assistant\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [response] To determine how much Janet makes every day at the farmers' market, let's break down the problem step by step:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 1. **Calculate the total number of eggs laid by the ducks per day:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    - Janet's ducks lay 16 eggs per day.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 2. **Calculate the number of eggs eaten for breakfast:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    - She eats 3 eggs for breakfast every morning.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    - Number of eggs left after breakfast: \\( 16 - 3 = 13 \\) eggs.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 3. **Calculate the number of eggs used for baking muffins:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    - She uses 4 eggs for baking muffins every day.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    - Number of eggs left after baking: \\( 13 - 4 = 9 \\) eggs.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 4. **Calculate the number of eggs sold at the farmers' market:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    - Number of eggs left after both breakfast and muffins: \\( 9 \\) eggs.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 5. **Calculate the revenue from selling the eggs at the farmers' market:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    - Janet sells the eggs at $2 per egg.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    - Total revenue: \\( 9 \\times 2 = 18 \\) dollars.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m So, Janet makes **$18** every day at the farmers' market.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [ground_truth] 18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [score] 0.0\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:5 - global_seqlen/min:387362.000 - global_seqlen/max:387362.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:387362.000 - global_seqlen/balanced_max:387362.000 - global_seqlen/mean:387362.000 - actor/reward_kl_penalty:-0.000 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.387 - actor/pg_loss:0.020 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.380 - perf/mfu/actor:0.661 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.289 - actor/lr:0.000 - val-core/openai/gsm8k/reward/mean@1:0.127 - val-aux/openai/gsm8k/reward/std@1:0.000 - val-core/openai/gsm8k/reward/best@1/mean:0.127 - val-core/openai/gsm8k/reward/best@1/std:0.000 - val-aux/openai/gsm8k/reward/worst@1/mean:0.127 - val-aux/openai/gsm8k/reward/worst@1/std:0.000 - critic/score/mean:0.127 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.127 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.020 - critic/advantages/max:2.475 - critic/advantages/min:-2.195 - critic/returns/mean:-0.020 - critic/returns/max:2.475 - critic/returns/min:-2.195 - response_length/mean:273.307 - response_length/max:1024.000 - response_length/min:4.000 - response_length/clip_ratio:0.002 - prompt_length/mean:104.977 - prompt_length/max:186.000 - prompt_length/min:70.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:26.809 - timing_s/old_log_prob:11.214 - timing_s/ref:11.308 - timing_s/adv:0.203 - timing_s/update_actor:43.293 - timing_s/testing:57.786 - timing_s/step:150.646 - timing_per_token_ms/gen:0.096 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:387362.000 - perf/time_per_step:150.646 - perf/throughput:2571.347\n",
      "Training Progress:   0%|          | 5/1160 [08:44<36:32:28, 113.90s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:34:04,206:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:6 - global_seqlen/min:388064.000 - global_seqlen/max:388064.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:388064.000 - global_seqlen/balanced_max:388064.000 - global_seqlen/mean:388064.000 - actor/reward_kl_penalty:-0.000 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.389 - actor/pg_loss:0.006 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.436 - perf/mfu/actor:0.656 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.330 - actor/lr:0.000 - critic/score/mean:0.127 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.127 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.007 - critic/advantages/max:2.475 - critic/advantages/min:-2.148 - critic/returns/mean:-0.007 - critic/returns/max:2.475 - critic/returns/min:-2.148 - response_length/mean:275.500 - response_length/max:1024.000 - response_length/min:5.000 - response_length/clip_ratio:0.001 - prompt_length/mean:103.469 - prompt_length/max:190.000 - prompt_length/min:67.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:26.434 - timing_s/old_log_prob:11.229 - timing_s/ref:11.313 - timing_s/adv:0.206 - timing_s/update_actor:43.694 - timing_s/step:92.919 - timing_per_token_ms/gen:0.094 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:388064.000 - perf/time_per_step:92.919 - perf/throughput:4176.385\n",
      "Training Progress:   1%|          | 6/1160 [10:17<34:13:30, 106.77s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:35:37,222:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:7 - global_seqlen/min:389489.000 - global_seqlen/max:389489.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:389489.000 - global_seqlen/balanced_max:389489.000 - global_seqlen/mean:389489.000 - actor/reward_kl_penalty:-0.000 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.420 - actor/pg_loss:0.039 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.361 - perf/mfu/actor:0.661 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.339 - actor/lr:0.000 - critic/score/mean:0.135 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.135 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.039 - critic/advantages/max:2.475 - critic/advantages/min:-2.241 - critic/returns/mean:-0.039 - critic/returns/max:2.475 - critic/returns/min:-2.241 - response_length/mean:276.110 - response_length/max:1024.000 - response_length/min:5.000 - response_length/clip_ratio:0.002 - prompt_length/mean:104.250 - prompt_length/max:206.000 - prompt_length/min:71.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:27.194 - timing_s/old_log_prob:11.268 - timing_s/ref:11.358 - timing_s/adv:0.204 - timing_s/update_actor:43.529 - timing_s/step:93.589 - timing_per_token_ms/gen:0.096 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:389489.000 - perf/time_per_step:93.589 - perf/throughput:4161.683\n",
      "Training Progress:   1%|          | 7/1160 [11:51<32:48:59, 102.46s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:37:10,819:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:8 - global_seqlen/min:385739.000 - global_seqlen/max:385739.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:385739.000 - global_seqlen/balanced_max:385739.000 - global_seqlen/mean:385739.000 - actor/reward_kl_penalty:0.000 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.379 - actor/pg_loss:0.021 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.416 - perf/mfu/actor:0.661 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.331 - actor/lr:0.000 - critic/score/mean:0.152 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.152 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.022 - critic/advantages/max:2.475 - critic/advantages/min:-2.108 - critic/returns/mean:-0.022 - critic/returns/max:2.475 - critic/returns/min:-2.108 - response_length/mean:273.620 - response_length/max:1017.000 - response_length/min:4.000 - response_length/clip_ratio:0.000 - prompt_length/mean:103.078 - prompt_length/max:199.000 - prompt_length/min:71.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:26.753 - timing_s/old_log_prob:11.181 - timing_s/ref:11.272 - timing_s/adv:0.203 - timing_s/update_actor:43.109 - timing_s/step:92.554 - timing_per_token_ms/gen:0.095 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:385739.000 - perf/time_per_step:92.554 - perf/throughput:4167.740\n",
      "Training Progress:   1%|          | 8/1160 [13:23<31:46:46, 99.31s/it] \n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:38:43,468:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:9 - global_seqlen/min:365946.000 - global_seqlen/max:365946.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:365946.000 - global_seqlen/balanced_max:365946.000 - global_seqlen/mean:365946.000 - actor/reward_kl_penalty:0.000 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.399 - actor/pg_loss:0.019 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.419 - perf/mfu/actor:0.655 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.328 - actor/lr:0.000 - critic/score/mean:0.148 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.148 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.019 - critic/advantages/max:2.475 - critic/advantages/min:-2.102 - critic/returns/mean:-0.019 - critic/returns/max:2.475 - critic/returns/min:-2.102 - response_length/mean:259.393 - response_length/max:929.000 - response_length/min:5.000 - response_length/clip_ratio:0.000 - prompt_length/mean:97.977 - prompt_length/max:147.000 - prompt_length/min:66.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:25.523 - timing_s/old_log_prob:10.645 - timing_s/ref:10.720 - timing_s/adv:0.197 - timing_s/update_actor:41.202 - timing_s/step:88.321 - timing_per_token_ms/gen:0.096 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:365946.000 - perf/time_per_step:88.321 - perf/throughput:4143.353\n",
      "Training Progress:   1%|          | 9/1160 [14:52<30:39:16, 95.88s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:40:11,715:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True}\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:41:48,740:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m validation generation end\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [prompt] system\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m user\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after \"####\".\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m assistant\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [response] #### 20\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Janet's ducks lay 16 eggs per day. She eats 3 eggs for breakfast, so she eats 3 eggs. The remainder is 16 - 3 = 13 eggs. She gives 4 eggs to friends to bake muffins, so she has 13 - 4 = 9 eggs left. Janet sells these 9 eggs for $2 each, which equals 9 * 2 = $18. The amount she makes every day at the farmers' market is $18.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [ground_truth] 18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [score] 0.0\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:10 - global_seqlen/min:396487.000 - global_seqlen/max:396487.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:396487.000 - global_seqlen/balanced_max:396487.000 - global_seqlen/mean:396487.000 - actor/reward_kl_penalty:0.000 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.417 - actor/pg_loss:0.029 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.393 - perf/mfu/actor:0.654 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.304 - actor/lr:0.000 - val-core/openai/gsm8k/reward/mean@1:0.180 - val-aux/openai/gsm8k/reward/std@1:0.000 - val-core/openai/gsm8k/reward/best@1/mean:0.180 - val-core/openai/gsm8k/reward/best@1/std:0.000 - val-aux/openai/gsm8k/reward/worst@1/mean:0.180 - val-aux/openai/gsm8k/reward/worst@1/std:0.000 - critic/score/mean:0.162 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.162 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.028 - critic/advantages/max:2.475 - critic/advantages/min:-2.201 - critic/returns/mean:-0.028 - critic/returns/max:2.475 - critic/returns/min:-2.201 - response_length/mean:285.358 - response_length/max:1024.000 - response_length/min:4.000 - response_length/clip_ratio:0.002 - prompt_length/mean:101.836 - prompt_length/max:256.000 - prompt_length/min:69.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:27.560 - timing_s/old_log_prob:11.522 - timing_s/ref:11.620 - timing_s/adv:0.205 - timing_s/update_actor:44.803 - timing_s/testing:56.886 - timing_s/step:152.632 - timing_per_token_ms/gen:0.094 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:396487.000 - perf/time_per_step:152.632 - perf/throughput:2597.672\n",
      "Training Progress:   1%|          | 10/1160 [17:24<36:13:34, 113.40s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:42:44,287:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:11 - global_seqlen/min:388758.000 - global_seqlen/max:388758.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:388758.000 - global_seqlen/balanced_max:388758.000 - global_seqlen/mean:388758.000 - actor/reward_kl_penalty:0.001 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.415 - actor/pg_loss:0.031 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.368 - perf/mfu/actor:0.647 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.355 - actor/lr:0.000 - critic/score/mean:0.182 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.182 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.030 - critic/advantages/max:2.475 - critic/advantages/min:-2.305 - critic/returns/mean:-0.030 - critic/returns/max:2.475 - critic/returns/min:-2.305 - response_length/mean:273.311 - response_length/max:1024.000 - response_length/min:4.000 - response_length/clip_ratio:0.002 - prompt_length/mean:106.336 - prompt_length/max:189.000 - prompt_length/min:67.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:26.448 - timing_s/old_log_prob:11.266 - timing_s/ref:11.365 - timing_s/adv:0.205 - timing_s/update_actor:44.362 - timing_s/step:93.683 - timing_per_token_ms/gen:0.094 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.114 - perf/total_num_tokens:388758.000 - perf/time_per_step:93.683 - perf/throughput:4149.696\n",
      "Training Progress:   1%|          | 11/1160 [18:58<34:16:11, 107.37s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:44:18,067:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:12 - global_seqlen/min:397225.000 - global_seqlen/max:397225.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:397225.000 - global_seqlen/balanced_max:397225.000 - global_seqlen/mean:397225.000 - actor/reward_kl_penalty:0.001 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.401 - actor/pg_loss:0.013 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.290 - perf/mfu/actor:0.655 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.328 - actor/lr:0.000 - critic/score/mean:0.177 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.177 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.013 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.013 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:285.063 - response_length/max:919.000 - response_length/min:4.000 - response_length/clip_ratio:0.000 - prompt_length/mean:102.852 - prompt_length/max:168.000 - prompt_length/min:68.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:26.855 - timing_s/old_log_prob:11.936 - timing_s/ref:11.692 - timing_s/adv:0.209 - timing_s/update_actor:44.781 - timing_s/step:95.511 - timing_per_token_ms/gen:0.092 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:397225.000 - perf/time_per_step:95.511 - perf/throughput:4158.942\n",
      "Training Progress:   1%|          | 12/1160 [20:34<33:05:25, 103.77s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:45:53,589:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:13 - global_seqlen/min:382427.000 - global_seqlen/max:382427.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:382427.000 - global_seqlen/balanced_max:382427.000 - global_seqlen/mean:382427.000 - actor/reward_kl_penalty:0.001 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.390 - actor/pg_loss:0.031 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.381 - perf/mfu/actor:0.655 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.328 - actor/lr:0.000 - critic/score/mean:0.201 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.201 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.031 - critic/advantages/max:2.475 - critic/advantages/min:-2.149 - critic/returns/mean:-0.031 - critic/returns/max:2.475 - critic/returns/min:-2.149 - response_length/mean:269.620 - response_length/max:1024.000 - response_length/min:4.000 - response_length/clip_ratio:0.001 - prompt_length/mean:103.844 - prompt_length/max:183.000 - prompt_length/min:70.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:26.368 - timing_s/old_log_prob:11.110 - timing_s/ref:11.190 - timing_s/adv:0.201 - timing_s/update_actor:43.124 - timing_s/step:92.026 - timing_per_token_ms/gen:0.096 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:382427.000 - perf/time_per_step:92.026 - perf/throughput:4155.645\n",
      "Training Progress:   1%|          | 13/1160 [22:06<31:55:48, 100.22s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:47:25,627:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:14 - global_seqlen/min:380384.000 - global_seqlen/max:380384.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:380384.000 - global_seqlen/balanced_max:380384.000 - global_seqlen/mean:380384.000 - actor/reward_kl_penalty:0.001 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.373 - actor/pg_loss:0.016 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.351 - perf/mfu/actor:0.653 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.335 - actor/lr:0.000 - critic/score/mean:0.201 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.201 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.016 - critic/advantages/max:2.475 - critic/advantages/min:-2.032 - critic/returns/mean:-0.016 - critic/returns/max:2.475 - critic/returns/min:-2.032 - response_length/mean:270.203 - response_length/max:1013.000 - response_length/min:4.000 - response_length/clip_ratio:0.000 - prompt_length/mean:101.266 - prompt_length/max:151.000 - prompt_length/min:63.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:26.178 - timing_s/old_log_prob:11.061 - timing_s/ref:11.154 - timing_s/adv:0.203 - timing_s/update_actor:43.011 - timing_s/step:91.641 - timing_per_token_ms/gen:0.095 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:380384.000 - perf/time_per_step:91.641 - perf/throughput:4150.811\n",
      "Training Progress:   1%|          | 14/1160 [23:37<31:04:44, 97.63s/it] \n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:48:57,284:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True}\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:50:31,141:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m validation generation end\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [prompt] system\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m user\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after \"####\".\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m assistant\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [response] To determine how much Janet makes every day at the farmers' market, let's break down the problem step by step:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 1. **Calculate the total number of eggs laid per day:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    Janet's ducks lay 16 eggs per day.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 2. **Calculate the number of eggs eaten for breakfast:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    Janet eats 3 eggs for breakfast every morning. Therefore, she eats \\(3 \\times \\text{number of days per week}\\) eggs per week. Since the number of days per week is not given, we'll assume it's the same as the number of days she's operating, which is typically 7 for a full week of business.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    So, the eggs eaten for breakfast per day = \\(3\\) eggs/day.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 3. **Calculate the number of eggs used for muffins:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    Janet bakes muffins for her friends with 4 eggs. Therefore, she uses \\(4\\) eggs per day for her muffins.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 4. **Calculate the total eggs used each day:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    - Eggs used for breakfast = \\(3\\) eggs/day\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    - Eggs used for muffins = \\(4\\) eggs/day\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    Total eggs used per day = \\(3 + 4 = 7\\) eggs/day.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 5. **Calculate the number of eggs left for selling at the market:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    Total eggs laid per day = \\(16\\) eggs\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    Eggs left for the market = \\(16 - 7 = 9\\) eggs/day.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 6. **Calculate the revenue from selling the eggs at the market:**\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    Janet sells the eggs at the market for $2 per egg. Therefore, the total revenue per day from selling eggs at the market = \\(9 \\times 2 = 18\\) dollars.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m So, Janet makes \\(\\boxed{18}\\) dollars every day at the farmers' market.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [ground_truth] 18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [score] 0.0\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:15 - global_seqlen/min:381390.000 - global_seqlen/max:381390.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:381390.000 - global_seqlen/balanced_max:381390.000 - global_seqlen/mean:381390.000 - actor/reward_kl_penalty:0.002 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.407 - actor/pg_loss:0.025 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.343 - perf/mfu/actor:0.652 - perf/max_memory_allocated_gb:100.411 - perf/max_memory_reserved_gb:107.678 - perf/cpu_memory_used_gb:10.333 - actor/lr:0.000 - val-core/openai/gsm8k/reward/mean@1:0.277 - val-aux/openai/gsm8k/reward/std@1:0.000 - val-core/openai/gsm8k/reward/best@1/mean:0.277 - val-core/openai/gsm8k/reward/best@1/std:0.000 - val-aux/openai/gsm8k/reward/worst@1/mean:0.277 - val-aux/openai/gsm8k/reward/worst@1/std:0.000 - critic/score/mean:0.250 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.250 - critic/rewards/max:1.000 - critic/rewards/min:-0.000 - critic/advantages/mean:-0.025 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.025 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:268.045 - response_length/max:1024.000 - response_length/min:6.000 - response_length/clip_ratio:0.001 - prompt_length/mean:104.406 - prompt_length/max:180.000 - prompt_length/min:68.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:26.833 - timing_s/old_log_prob:11.096 - timing_s/ref:11.185 - timing_s/adv:0.201 - timing_s/update_actor:43.224 - timing_s/testing:57.103 - timing_s/step:149.677 - timing_per_token_ms/gen:0.098 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:381390.000 - perf/time_per_step:149.677 - perf/throughput:2548.079\n",
      "Training Progress:   1%|▏         | 15/1160 [26:07<36:02:33, 113.32s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:51:26,890:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:16 - global_seqlen/min:383887.000 - global_seqlen/max:383887.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:383887.000 - global_seqlen/balanced_max:383887.000 - global_seqlen/mean:383887.000 - actor/reward_kl_penalty:0.004 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.378 - actor/pg_loss:0.031 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.334 - perf/mfu/actor:0.657 - perf/max_memory_allocated_gb:100.431 - perf/max_memory_reserved_gb:107.686 - perf/cpu_memory_used_gb:10.335 - actor/lr:0.000 - critic/score/mean:0.289 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.289 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.031 - critic/advantages/max:2.475 - critic/advantages/min:-2.146 - critic/returns/mean:-0.031 - critic/returns/max:2.475 - critic/returns/min:-2.146 - response_length/mean:273.132 - response_length/max:1024.000 - response_length/min:4.000 - response_length/clip_ratio:0.001 - prompt_length/mean:101.758 - prompt_length/max:169.000 - prompt_length/min:68.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:26.227 - timing_s/old_log_prob:11.129 - timing_s/ref:11.669 - timing_s/adv:0.205 - timing_s/update_actor:43.133 - timing_s/step:92.405 - timing_per_token_ms/gen:0.094 - timing_per_token_ms/ref:0.030 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:383887.000 - perf/time_per_step:92.405 - perf/throughput:4154.390\n",
      "Training Progress:   1%|▏         | 16/1160 [27:39<34:00:41, 107.03s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:52:59,385:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:17 - global_seqlen/min:377517.000 - global_seqlen/max:377517.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:377517.000 - global_seqlen/balanced_max:377517.000 - global_seqlen/mean:377517.000 - actor/reward_kl_penalty:0.004 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.390 - actor/pg_loss:0.027 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.322 - perf/mfu/actor:0.654 - perf/max_memory_allocated_gb:100.431 - perf/max_memory_reserved_gb:107.686 - perf/cpu_memory_used_gb:10.317 - actor/lr:0.000 - critic/score/mean:0.298 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.298 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.027 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.027 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:264.903 - response_length/max:890.000 - response_length/min:4.000 - response_length/clip_ratio:0.000 - prompt_length/mean:103.766 - prompt_length/max:184.000 - prompt_length/min:68.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:24.935 - timing_s/old_log_prob:11.309 - timing_s/ref:10.990 - timing_s/adv:0.204 - timing_s/update_actor:42.614 - timing_s/step:90.099 - timing_per_token_ms/gen:0.092 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:377517.000 - perf/time_per_step:90.099 - perf/throughput:4190.004\n",
      "Training Progress:   1%|▏         | 17/1160 [29:10<32:21:59, 101.94s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:54:29,493:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:18 - global_seqlen/min:386192.000 - global_seqlen/max:386192.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:386192.000 - global_seqlen/balanced_max:386192.000 - global_seqlen/mean:386192.000 - actor/reward_kl_penalty:0.004 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.388 - actor/pg_loss:0.031 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.324 - perf/mfu/actor:0.655 - perf/max_memory_allocated_gb:100.431 - perf/max_memory_reserved_gb:107.686 - perf/cpu_memory_used_gb:10.341 - actor/lr:0.000 - critic/score/mean:0.367 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.367 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.031 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.031 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:273.125 - response_length/max:835.000 - response_length/min:5.000 - response_length/clip_ratio:0.000 - prompt_length/mean:104.016 - prompt_length/max:201.000 - prompt_length/min:72.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:24.990 - timing_s/old_log_prob:11.603 - timing_s/ref:11.271 - timing_s/adv:0.202 - timing_s/update_actor:43.553 - timing_s/step:91.663 - timing_per_token_ms/gen:0.089 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:386192.000 - perf/time_per_step:91.663 - perf/throughput:4213.179\n",
      "Training Progress:   2%|▏         | 18/1160 [30:41<31:21:34, 98.86s/it] \n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:56:01,173:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:19 - global_seqlen/min:369188.000 - global_seqlen/max:369188.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:369188.000 - global_seqlen/balanced_max:369188.000 - global_seqlen/mean:369188.000 - actor/reward_kl_penalty:0.005 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.345 - actor/pg_loss:0.043 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.404 - perf/mfu/actor:0.653 - perf/max_memory_allocated_gb:100.431 - perf/max_memory_reserved_gb:107.686 - perf/cpu_memory_used_gb:10.341 - actor/lr:0.000 - critic/score/mean:0.375 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.375 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.043 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.043 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:257.184 - response_length/max:859.000 - response_length/min:5.000 - response_length/clip_ratio:0.000 - prompt_length/mean:103.352 - prompt_length/max:184.000 - prompt_length/min:71.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:24.481 - timing_s/old_log_prob:10.728 - timing_s/ref:10.822 - timing_s/adv:0.201 - timing_s/update_actor:41.691 - timing_s/step:87.956 - timing_per_token_ms/gen:0.093 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:369188.000 - perf/time_per_step:87.956 - perf/throughput:4197.419\n",
      "Training Progress:   2%|▏         | 19/1160 [32:09<30:17:45, 95.59s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:57:29,220:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True}\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:58:57,240:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m validation generation end\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [prompt] system\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m user\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after \"####\".\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m assistant\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [response] To determine how much Janet makes every day at the farmers' market, let's break down the problem step by step:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 1. **Total eggs laid per day**: 16 eggs.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 2. **Eggs eaten for breakfast**: Janet eats 3 eggs per morning, so after breakfast, she has:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\[\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    16 - 3 = 13 \\text{ eggs}\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 3. **Eggs used for muffins**: Janet uses 4 eggs for baking muffins, leaving her with:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\[\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    13 - 4 = 9 \\text{ eggs}\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 4. **Eggs remaining for sale**: She has 9 eggs left after using some for breakfast and baking muffins. These eggs are sold at $2 per egg, so she earns:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\[\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    9 \\times 2 = 18 \\text{ dollars}\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Therefore, Janet makes $18 every day at the farmers' market.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m #### The final answer is 18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [ground_truth] 18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [score] 0.0\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:20 - global_seqlen/min:367661.000 - global_seqlen/max:367661.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:367661.000 - global_seqlen/balanced_max:367661.000 - global_seqlen/mean:367661.000 - actor/reward_kl_penalty:0.005 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.376 - actor/pg_loss:0.029 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.353 - perf/mfu/actor:0.656 - perf/max_memory_allocated_gb:100.431 - perf/max_memory_reserved_gb:107.686 - perf/cpu_memory_used_gb:10.345 - actor/lr:0.000 - val-core/openai/gsm8k/reward/mean@1:0.374 - val-aux/openai/gsm8k/reward/std@1:0.000 - val-core/openai/gsm8k/reward/best@1/mean:0.374 - val-core/openai/gsm8k/reward/best@1/std:0.000 - val-aux/openai/gsm8k/reward/worst@1/mean:0.374 - val-aux/openai/gsm8k/reward/worst@1/std:0.000 - critic/score/mean:0.398 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.398 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.029 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.029 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:256.130 - response_length/max:778.000 - response_length/min:5.000 - response_length/clip_ratio:0.000 - prompt_length/mean:102.914 - prompt_length/max:171.000 - prompt_length/min:69.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:23.800 - timing_s/old_log_prob:10.673 - timing_s/ref:10.764 - timing_s/adv:0.204 - timing_s/update_actor:41.321 - timing_s/testing:56.168 - timing_s/step:142.965 - timing_per_token_ms/gen:0.091 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:367661.000 - perf/time_per_step:142.965 - perf/throughput:2571.690\n",
      "Training Progress:   2%|▏         | 20/1160 [34:32<34:46:34, 109.82s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 11:59:52,056:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:21 - global_seqlen/min:374243.000 - global_seqlen/max:374243.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:374243.000 - global_seqlen/balanced_max:374243.000 - global_seqlen/mean:374243.000 - actor/reward_kl_penalty:0.007 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.379 - actor/pg_loss:0.031 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.347 - perf/mfu/actor:0.656 - perf/max_memory_allocated_gb:100.431 - perf/max_memory_reserved_gb:107.686 - perf/cpu_memory_used_gb:10.382 - actor/lr:0.000 - critic/score/mean:0.363 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.363 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.032 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.032 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:258.964 - response_length/max:879.000 - response_length/min:4.000 - response_length/clip_ratio:0.000 - prompt_length/mean:106.508 - prompt_length/max:183.000 - prompt_length/min:73.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:24.728 - timing_s/old_log_prob:10.813 - timing_s/ref:10.901 - timing_s/adv:0.204 - timing_s/update_actor:42.113 - timing_s/step:88.804 - timing_per_token_ms/gen:0.093 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:374243.000 - perf/time_per_step:88.804 - perf/throughput:4214.255\n",
      "Training Progress:   2%|▏         | 21/1160 [36:01<32:45:05, 103.52s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:01:20,950:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:22 - global_seqlen/min:357651.000 - global_seqlen/max:357651.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:357651.000 - global_seqlen/balanced_max:357651.000 - global_seqlen/mean:357651.000 - actor/reward_kl_penalty:0.007 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.387 - actor/pg_loss:0.032 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.403 - perf/mfu/actor:0.662 - perf/max_memory_allocated_gb:100.431 - perf/max_memory_reserved_gb:108.080 - perf/cpu_memory_used_gb:10.381 - actor/lr:0.000 - critic/score/mean:0.431 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.431 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.032 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.032 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:246.956 - response_length/max:1024.000 - response_length/min:4.000 - response_length/clip_ratio:0.002 - prompt_length/mean:102.312 - prompt_length/max:175.000 - prompt_length/min:72.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:25.136 - timing_s/old_log_prob:10.361 - timing_s/ref:10.446 - timing_s/adv:0.196 - timing_s/update_actor:39.888 - timing_s/step:86.065 - timing_per_token_ms/gen:0.099 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:357651.000 - perf/time_per_step:86.065 - perf/throughput:4155.588\n",
      "Training Progress:   2%|▏         | 22/1160 [37:27<31:04:05, 98.28s/it] \n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:02:47,031:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:23 - global_seqlen/min:368304.000 - global_seqlen/max:368304.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:368304.000 - global_seqlen/balanced_max:368304.000 - global_seqlen/mean:368304.000 - actor/reward_kl_penalty:0.010 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.432 - actor/pg_loss:0.035 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.345 - perf/mfu/actor:0.655 - perf/max_memory_allocated_gb:100.445 - perf/max_memory_reserved_gb:108.080 - perf/cpu_memory_used_gb:10.381 - actor/lr:0.000 - critic/score/mean:0.483 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.483 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.035 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.035 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:256.656 - response_length/max:815.000 - response_length/min:4.000 - response_length/clip_ratio:0.000 - prompt_length/mean:103.016 - prompt_length/max:196.000 - prompt_length/min:68.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:24.000 - timing_s/old_log_prob:10.666 - timing_s/ref:10.762 - timing_s/adv:0.206 - timing_s/update_actor:41.497 - timing_s/step:87.168 - timing_per_token_ms/gen:0.091 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:368304.000 - perf/time_per_step:87.168 - perf/throughput:4225.223\n",
      "Training Progress:   2%|▏         | 23/1160 [38:54<29:59:19, 94.95s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:04:14,208:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:24 - global_seqlen/min:352605.000 - global_seqlen/max:352605.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:352605.000 - global_seqlen/balanced_max:352605.000 - global_seqlen/mean:352605.000 - actor/reward_kl_penalty:0.011 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.353 - actor/pg_loss:0.024 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.364 - perf/mfu/actor:0.660 - perf/max_memory_allocated_gb:100.445 - perf/max_memory_reserved_gb:108.080 - perf/cpu_memory_used_gb:10.373 - actor/lr:0.000 - critic/score/mean:0.564 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.564 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.025 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.025 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:240.661 - response_length/max:856.000 - response_length/min:5.000 - response_length/clip_ratio:0.000 - prompt_length/mean:103.680 - prompt_length/max:170.000 - prompt_length/min:69.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:22.794 - timing_s/old_log_prob:10.220 - timing_s/ref:10.315 - timing_s/adv:0.196 - timing_s/update_actor:39.417 - timing_s/step:82.982 - timing_per_token_ms/gen:0.092 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:352605.000 - perf/time_per_step:82.982 - perf/throughput:4249.195\n",
      "Training Progress:   2%|▏         | 24/1160 [40:17<28:49:48, 91.36s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:05:37,204:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True}\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:07:02,630:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m validation generation end\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [prompt] system\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m user\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after \"####\".\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m assistant\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [response] To determine how much Janet makes every day at the farmers' market, we'll break down the problem step by step:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 1. **Daily Egg Production:** Janet's ducks lay 16 eggs per day.\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 2. **Eggs for Breakfast:** Janet eats three eggs every morning. So, the number of eggs left after breakfast is:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\[\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    16 - 3 = 13 \\text{ eggs}\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 3. **Eggs for Muffins:** She also bakes muffins for her friends, using four of those eggs. So, the number of eggs left after baking muffins is:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\[\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    13 - 4 = 9 \\text{ eggs}\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 4. **Eggs for Market:** The remainder of the eggs are sold at the farmers' market. Therefore, the number of eggs sold daily is:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\[\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    9 \\text{ eggs}\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m 5. **Earnings from Eggs:** Janet sells each fresh duck egg for $2. Thus, the total earnings from selling the eggs are:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\[\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    9 \\text{ eggs} \\times \\$2/\\text{egg} = \\$18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m    \\]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m Thus, the total amount Janet makes every day at the farmers' market is $18. The final answer is:\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m #### 18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [ground_truth] 18\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m [score] 1.0\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:25 - global_seqlen/min:356930.000 - global_seqlen/max:356930.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:356930.000 - global_seqlen/balanced_max:356930.000 - global_seqlen/mean:356930.000 - actor/reward_kl_penalty:0.017 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.350 - actor/pg_loss:0.025 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.332 - perf/mfu/actor:0.657 - perf/max_memory_allocated_gb:100.445 - perf/max_memory_reserved_gb:108.080 - perf/cpu_memory_used_gb:10.374 - actor/lr:0.000 - val-core/openai/gsm8k/reward/mean@1:0.566 - val-aux/openai/gsm8k/reward/std@1:0.000 - val-core/openai/gsm8k/reward/best@1/mean:0.566 - val-core/openai/gsm8k/reward/best@1/std:0.000 - val-aux/openai/gsm8k/reward/worst@1/mean:0.566 - val-aux/openai/gsm8k/reward/worst@1/std:0.000 - critic/score/mean:0.597 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.596 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.025 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.025 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:244.002 - response_length/max:856.000 - response_length/min:5.000 - response_length/clip_ratio:0.000 - prompt_length/mean:104.562 - prompt_length/max:189.000 - prompt_length/min:70.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:22.797 - timing_s/old_log_prob:10.637 - timing_s/ref:10.410 - timing_s/adv:0.198 - timing_s/update_actor:40.056 - timing_s/testing:52.388 - timing_s/step:136.527 - timing_per_token_ms/gen:0.091 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:356930.000 - perf/time_per_step:136.527 - perf/throughput:2614.346\n",
      "Training Progress:   2%|▏         | 25/1160 [42:34<33:04:42, 104.92s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:07:53,667:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:26 - global_seqlen/min:352096.000 - global_seqlen/max:352096.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:352096.000 - global_seqlen/balanced_max:352096.000 - global_seqlen/mean:352096.000 - actor/reward_kl_penalty:0.016 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.385 - actor/pg_loss:0.029 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.326 - perf/mfu/actor:0.659 - perf/max_memory_allocated_gb:100.453 - perf/max_memory_reserved_gb:108.080 - perf/cpu_memory_used_gb:10.379 - actor/lr:0.000 - critic/score/mean:0.588 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.588 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.030 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.030 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:239.023 - response_length/max:889.000 - response_length/min:4.000 - response_length/clip_ratio:0.000 - prompt_length/mean:104.820 - prompt_length/max:174.000 - prompt_length/min:68.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:22.790 - timing_s/old_log_prob:10.222 - timing_s/ref:10.310 - timing_s/adv:0.200 - timing_s/update_actor:39.404 - timing_s/step:82.970 - timing_per_token_ms/gen:0.093 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:352096.000 - perf/time_per_step:82.970 - perf/throughput:4243.636\n",
      "Training Progress:   2%|▏         | 26/1160 [43:57<30:58:35, 98.34s/it] \n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:09:16,740:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:27 - global_seqlen/min:343070.000 - global_seqlen/max:343070.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:343070.000 - global_seqlen/balanced_max:343070.000 - global_seqlen/mean:343070.000 - actor/reward_kl_penalty:0.020 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.393 - actor/pg_loss:0.011 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.328 - perf/mfu/actor:0.653 - perf/max_memory_allocated_gb:100.453 - perf/max_memory_reserved_gb:108.080 - perf/cpu_memory_used_gb:10.393 - actor/lr:0.000 - critic/score/mean:0.639 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.638 - critic/rewards/max:1.000 - critic/rewards/min:-0.001 - critic/advantages/mean:-0.012 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.012 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:231.631 - response_length/max:898.000 - response_length/min:4.000 - response_length/clip_ratio:0.000 - prompt_length/mean:103.398 - prompt_length/max:173.000 - prompt_length/min:66.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:22.083 - timing_s/old_log_prob:9.918 - timing_s/ref:10.001 - timing_s/adv:0.193 - timing_s/update_actor:38.718 - timing_s/step:80.957 - timing_per_token_ms/gen:0.093 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:343070.000 - perf/time_per_step:80.957 - perf/throughput:4237.672\n",
      "Training Progress:   2%|▏         | 27/1160 [45:18<29:18:35, 93.13s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:10:37,718:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:28 - global_seqlen/min:343187.000 - global_seqlen/max:343187.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:343187.000 - global_seqlen/balanced_max:343187.000 - global_seqlen/mean:343187.000 - actor/reward_kl_penalty:0.020 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.393 - actor/pg_loss:0.017 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.337 - perf/mfu/actor:0.659 - perf/max_memory_allocated_gb:100.453 - perf/max_memory_reserved_gb:108.080 - perf/cpu_memory_used_gb:10.361 - actor/lr:0.000 - critic/score/mean:0.646 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.645 - critic/rewards/max:1.000 - critic/rewards/min:-0.002 - critic/advantages/mean:-0.017 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:-0.017 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:231.558 - response_length/max:825.000 - response_length/min:5.000 - response_length/clip_ratio:0.000 - prompt_length/mean:103.586 - prompt_length/max:199.000 - prompt_length/min:65.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:21.573 - timing_s/old_log_prob:9.927 - timing_s/ref:10.002 - timing_s/adv:0.197 - timing_s/update_actor:38.406 - timing_s/step:80.146 - timing_per_token_ms/gen:0.091 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.112 - perf/total_num_tokens:343187.000 - perf/time_per_step:80.146 - perf/throughput:4282.045\n",
      "Training Progress:   2%|▏         | 28/1160 [46:38<28:03:37, 89.24s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:11:57,882:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m step:29 - global_seqlen/min:346864.000 - global_seqlen/max:346864.000 - global_seqlen/minmax_diff:0.000 - global_seqlen/balanced_min:346864.000 - global_seqlen/balanced_max:346864.000 - global_seqlen/mean:346864.000 - actor/reward_kl_penalty:0.018 - actor/reward_kl_penalty_coeff:0.000 - actor/entropy:0.419 - actor/pg_loss:-0.001 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/pg_clipfrac_lower:0.000 - actor/grad_norm:0.339 - perf/mfu/actor:0.653 - perf/max_memory_allocated_gb:100.453 - perf/max_memory_reserved_gb:108.080 - perf/cpu_memory_used_gb:10.371 - actor/lr:0.000 - critic/score/mean:0.588 - critic/score/max:1.000 - critic/score/min:0.000 - critic/rewards/mean:0.588 - critic/rewards/max:1.000 - critic/rewards/min:-0.002 - critic/advantages/mean:0.000 - critic/advantages/max:2.475 - critic/advantages/min:-2.475 - critic/returns/mean:0.000 - critic/returns/max:2.475 - critic/returns/min:-2.475 - response_length/mean:236.547 - response_length/max:772.000 - response_length/min:4.000 - response_length/clip_ratio:0.000 - prompt_length/mean:102.188 - prompt_length/max:157.000 - prompt_length/min:72.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:21.807 - timing_s/old_log_prob:10.103 - timing_s/ref:10.195 - timing_s/adv:0.194 - timing_s/update_actor:39.180 - timing_s/step:81.517 - timing_per_token_ms/gen:0.090 - timing_per_token_ms/ref:0.029 - timing_per_token_ms/adv:0.001 - timing_per_token_ms/update_actor:0.113 - perf/total_num_tokens:346864.000 - perf/time_per_step:81.517 - perf/throughput:4255.113\n",
      "Training Progress:   2%|▎         | 29/1160 [47:59<27:18:35, 86.93s/it]\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:13:19,442:vLLM load weights, loaded_params: 198\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m list(reward_extra_infos_dict.keys())=[]\n",
      "\u001b[36m(TaskRunner pid=1226029)\u001b[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True}\n",
      "\u001b[36m(WorkerDict pid=1226374)\u001b[0m INFO:2025-04-16 12:14:40,829:vLLM load weights, loaded_params: 198\n"
     ]
    }
   ],
   "source": [
    "os.environ.update({\n",
    "    k: str(v) for k, v in {\n",
    "        \"train_max_token_num_per_gpu\": int(1024 * 8),\n",
    "        \"infer_max_token_num_per_gpu\": int(1024 * 32),\n",
    "    }.items()\n",
    "})\n",
    "! python3 -m verl.trainer.main_ppo \\\n",
    "    algorithm.adv_estimator=grpo \\\n",
    "    data.train_files=[${TRAIN_FILE}] \\\n",
    "    data.val_files=[${TEST_FILE}] \\\n",
    "    data.max_prompt_length=512 \\\n",
    "    data.max_response_length=1024 \\\n",
    "    data.train_batch_size=128 \\\n",
    "    algorithm.use_kl_in_reward=True \\\n",
    "    algorithm.kl_ctrl.kl_coef=0.0001 \\\n",
    "    actor_rollout_ref.model.path=${MODEL_ID} \\\n",
    "    actor_rollout_ref.model.use_remove_padding=True \\\n",
    "    actor_rollout_ref.model.enable_gradient_checkpointing=True \\\n",
    "    actor_rollout_ref.actor.entropy_coeff=0.001 \\\n",
    "    actor_rollout_ref.actor.optim.lr=5e-7 \\\n",
    "    actor_rollout_ref.actor.optim.lr_warmup_steps=10 \\\n",
    "    actor_rollout_ref.actor.clip_ratio_low=0.2 \\\n",
    "    actor_rollout_ref.actor.clip_ratio_high=0.2 \\\n",
    "    actor_rollout_ref.actor.clip_ratio_c=10.0 \\\n",
    "    actor_rollout_ref.actor.ppo_mini_batch_size=128 \\\n",
    "    actor_rollout_ref.actor.use_dynamic_bsz=True \\\n",
    "    actor_rollout_ref.actor.ppo_max_token_len_per_gpu=\"${train_max_token_num_per_gpu}\" \\\n",
    "    actor_rollout_ref.rollout.n=8 \\\n",
    "    actor_rollout_ref.rollout.temperature=1.0 \\\n",
    "    actor_rollout_ref.rollout.top_p=1.0 \\\n",
    "    actor_rollout_ref.rollout.val_kwargs.temperature=1.0 \\\n",
    "    actor_rollout_ref.rollout.val_kwargs.top_p=0.95 \\\n",
    "    actor_rollout_ref.rollout.val_kwargs.do_sample=True \\\n",
    "    actor_rollout_ref.rollout.val_kwargs.n=1 \\\n",
    "    actor_rollout_ref.rollout.gpu_memory_utilization=0.8 \\\n",
    "    actor_rollout_ref.rollout.tensor_model_parallel_size=1 \\\n",
    "    actor_rollout_ref.rollout.enable_chunked_prefill=True \\\n",
    "    actor_rollout_ref.rollout.max_num_batched_tokens=10240 \\\n",
    "    actor_rollout_ref.rollout.log_prob_use_dynamic_bsz=True \\\n",
    "    actor_rollout_ref.rollout.log_prob_max_token_len_per_gpu=${infer_max_token_num_per_gpu} \\\n",
    "    actor_rollout_ref.ref.log_prob_use_dynamic_bsz=True  \\\n",
    "    actor_rollout_ref.ref.log_prob_max_token_len_per_gpu=${infer_max_token_num_per_gpu} \\\n",
    "    trainer.total_epochs=20 \\\n",
    "    trainer.val_before_train=True \\\n",
    "    trainer.test_freq=5 \\\n",
    "    trainer.save_freq=-1 \\\n",
    "    trainer.resume_mode=disable \\\n",
    "    trainer.nnodes=1 \\\n",
    "    trainer.n_gpus_per_node=1 \\\n",
    "    trainer.logger=[\"console\"] \\\n",
    "    trainer.project_name=\"verl-demo\" \\\n",
    "    trainer.experiment_name=\"grpo-gsm8k-$(basename ${MODEL_ID,,})\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
